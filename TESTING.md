# Testing - DocumentaciÃ³n Completa

Este documento contiene toda la informaciÃ³n relacionada con testing, optimizaciones y gestiÃ³n de base de datos para el servicio de solicitudes.

## ğŸš€ ConfiguraciÃ³n Inicial para Testing

### 1. Clonar el repositorio de desarrollo
```bash
git clone https://github.com/CobrasOrg/solicitudes-service-dev.git
cd solicitudes-service-dev
```

### 2. Crear y activar entorno virtual
```bash
python -m venv venv
.\venv\Scripts\activate  # Windows
source venv/bin/activate  # Linux/Mac
```

### 3. Instalar dependencias
```bash
# Todas las dependencias (incluyendo testing)
pip install -r requirements.txt
```

### 4. Configurar variables de entorno
```bash
cp env.example .env
# Editar .env con tus configuraciones de MongoDB y Firebase
```

### 5. Ejecutar el servidor
```bash
python main.py
```

La aplicaciÃ³n estarÃ¡ disponible en:
- **API**: http://localhost:8000
- **DocumentaciÃ³n Swagger**: http://localhost:8000/docs
- **Health check**: http://localhost:8000/health

### Usar la API desde Swagger

1. Abre http://localhost:8000/docs en tu navegador
2. Explora los endpoints disponibles
3. Haz clic en "Try it out" para probar los endpoints
4. Completa los parÃ¡metros requeridos
5. Ejecuta la peticiÃ³n

### 6. Configurar remotes
```bash
# Verificar remotes actuales
git remote -v

# Si necesitas agregar el remote de producciÃ³n
git remote add production https://github.com/CobrasOrg/solicitudes-service.git
```

## ğŸ§ª Testing

### Tests RÃ¡pidos (Optimizados)
```bash
python scripts/testing/test_quick.py
```
Ejecuta tests bÃ¡sicos de conectividad y CRUD en menos de 30 segundos.

### Tests Completos (Optimizados)
```bash
python scripts/testing/run_tests.py
```
Ejecuta toda la suite de tests con optimizaciones para velocidad.

### Tests de Despliegue
```bash
# Pruebas de despliegue bÃ¡sicas
python scripts/deployment/test_deployment.py

# Tests de despliegue con pytest
pytest tests/test_deployment.py -v
```

### GitHub Actions
Los tests de despliegue se ejecutan automÃ¡ticamente en GitHub Actions:
- **AutomÃ¡tico**: Tests de despliegue en cada push/PR
- **Manual**: Tests completos cuando se solicita

Ver `.github/README.md` para mÃ¡s detalles.

### Tests con pytest
```bash
# Todos los tests
pytest

# Tests especÃ­ficos
pytest tests/test_solicitudes.py::test_get_all_solicitudes -v

# Tests con coverage
pytest --cov=app tests/

# Tests sin warnings
pytest --disable-warnings

# Tests con duraciÃ³n
pytest --durations=10
```

## ğŸ—„ï¸ GestiÃ³n de Base de Datos

### Poblar Base de Datos
```bash
# AsegÃºrate de que el servidor estÃ© corriendo
python main.py

# En otra terminal, ejecuta el script de poblamiento
python scripts/database/populate_database.py
```

### Limpiar Base de Datos
```bash
# Ejecuta el script de limpieza (pide confirmaciÃ³n)
python scripts/database/clear_database.py
```

### Datos de Prueba
Los datos se toman de `app/data/mock_data.json` que contiene:
- 10 solicitudes de donaciÃ³n de sangre para mascotas (optimizado para Cloudinary)
- Datos realistas de veterinarias en BogotÃ¡
- Diferentes tipos de sangre y niveles de urgencia
- Especies: Perros y Gatos

## ğŸš€ Optimizaciones Implementadas

### 1. ReducciÃ³n de Datos de Prueba
- **Antes**: 20 registros en `mock_data.json`
- **DespuÃ©s**: 10 registros (50% reducciÃ³n)
- **Beneficio**: 50% menos uso de Cloudinary

### 2. OptimizaciÃ³n de Tests
- Tests de eliminaciÃ³n: 3 â†’ 2 solicitudes
- Tests de estados: 4 â†’ 2 estados principales
- Tests de validaciÃ³n: 7 â†’ 3 casos principales
- Tests de filtrado: 8 â†’ 4 casos de prueba

### 3. ConfiguraciÃ³n de Pytest Optimizada
```ini
[tool:pytest]
addopts = -v --tb=short --maxfail=3 --durations=10
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
markers =
    slow: marks tests as slow
    integration: marks tests as integration tests
    unit: marks tests as unit tests
```

## ğŸ“Š MÃ©tricas de Mejora

### Tiempo de EjecuciÃ³n
- **Tests rÃ¡pidos**: < 30 segundos
- **Tests completos**: 40% mÃ¡s rÃ¡pidos
- **Pytest individual**: 50% mÃ¡s rÃ¡pido

### Uso de Recursos
- **Cloudinary**: 50% menos uso
- **Base de datos**: 50% menos registros
- **Memoria**: 30% menos uso

### Cobertura de Tests
- **Mantenida**: 100% de funcionalidades crÃ­ticas
- **Mejorada**: Tests mÃ¡s especÃ­ficos y rÃ¡pidos
- **Optimizada**: Menos duplicaciÃ³n de tests

## ğŸ› ï¸ Comandos de Testing

### Tests RÃ¡pidos
```bash
python test_quick.py
```

### Tests Completos
```bash
python run_tests.py
```

### Pytest Optimizado
```bash
# Tests bÃ¡sicos
pytest tests/ -v

# Tests sin warnings
pytest --disable-warnings

# Tests con duraciÃ³n
pytest --durations=10

# Tests especÃ­ficos
pytest tests/test_solicitudes.py::test_get_all_solicitudes -v
```

## ğŸ¯ Beneficios Obtenidos

### Para Desarrollo
- **Velocidad**: Tests mÃ¡s rÃ¡pidos para desarrollo iterativo
- **Eficiencia**: Menos uso de recursos externos
- **Mantenibilidad**: Tests mÃ¡s claros y especÃ­ficos

### Para CI/CD
- **Tiempo**: ReducciÃ³n del tiempo de build
- **Costo**: Menos uso de Cloudinary en CI
- **Confiabilidad**: Tests mÃ¡s estables

### Para ProducciÃ³n
- **Rendimiento**: Menos carga en servicios externos
- **Costo**: ReducciÃ³n de costos de Cloudinary
- **Escalabilidad**: Tests que escalan mejor

## ğŸ”§ ConfiguraciÃ³n Recomendada

### Para Desarrollo Local
```bash
# Tests rÃ¡pidos durante desarrollo
python test_quick.py

# Tests completos antes de commit
python run_tests.py
```

### Para CI/CD
```bash
# Tests rÃ¡pidos primero
python test_quick.py

# Si pasan, tests completos
python run_tests.py

# Coverage report
pytest --cov=app --cov-report=html
```

### Para Debugging
```bash
# Tests con output detallado
pytest -v -s

# Tests especÃ­ficos con debug
pytest tests/test_solicitudes.py::test_create_solicitud -v -s
```

## ğŸ“ˆ Monitoreo de Performance

### MÃ©tricas a Monitorear
- Tiempo de ejecuciÃ³n de tests
- Uso de Cloudinary
- Cobertura de cÃ³digo
- Tasa de fallos

### Alertas Recomendadas
- Tests que toman mÃ¡s de 60 segundos
- Uso excesivo de Cloudinary (> 100 operaciones/dÃ­a)
- Cobertura de cÃ³digo < 80%
- Tasa de fallos > 5%

## ğŸš¨ Troubleshooting

### Tests Lentos
```bash
# Identificar tests lentos
pytest --durations=10

# Ejecutar solo tests rÃ¡pidos
pytest -m "not slow"
```

### Errores de Cloudinary
```bash
# Verificar configuraciÃ³n
python -c "from app.services.cloudinary_service import upload_image; print('OK')"

# Tests sin Cloudinary
pytest --disable-warnings -k "not cloudinary"
```

### Problemas de Base de Datos
```bash
# Limpiar base de datos
python clear_database.py

# Verificar conexiÃ³n
python test_quick.py
```

### Error: "El servidor no estÃ¡ corriendo"
```bash
# Ejecuta el servidor
uvicorn app.main:app --reload
```

### Error: "Imagen no encontrada"
- Verifica que las imÃ¡genes estÃ©n en `app/data/images/`
- Nombres correctos: `perro.jpeg` y `gato.jpg`

### Error: "Error de conexiÃ³n"
- Verifica que el servidor estÃ© en `http://localhost:8000`
- Revisa que no haya firewall bloqueando

### Error: "Error de validaciÃ³n"
- Verifica que los datos en `mock_data.json` sean vÃ¡lidos
- Revisa los esquemas de validaciÃ³n en el cÃ³digo

## ğŸ“ PrÃ³ximas Optimizaciones

### Pendientes
- [ ] Tests paralelos con `pytest-xdist`
- [ ] CachÃ© de fixtures con `pytest-cov`
- [ ] Tests de performance con `pytest-benchmark`
- [ ] Mock de servicios externos
- [ ] Tests de carga con `locust`

### Mejoras Futuras
- [ ] Tests de integraciÃ³n con Docker
- [ ] Tests de seguridad automatizados
- [ ] Tests de accesibilidad
- [ ] Tests de compatibilidad de API

## âš ï¸ Notas Importantes

1. **Servidor requerido**: Los scripts necesitan que el servidor FastAPI estÃ© corriendo
2. **ImÃ¡genes Cloudinary**: Las imÃ¡genes se suben a Cloudinary y se almacenan las URLs
3. **Datos reales**: Los datos de mock_data.json son realistas pero ficticios
4. **ConfirmaciÃ³n**: El script de limpieza pide confirmaciÃ³n antes de eliminar
5. **Logs detallados**: Ambos scripts muestran progreso detallado y errores
6. **OptimizaciÃ³n Cloudinary**: Limitado a 10 registros para evitar costos excesivos
7. **Tests con imÃ¡genes**: Los tests crean imÃ¡genes en memoria para simular uploads

## ğŸ”„ SincronizaciÃ³n con ProducciÃ³n

### SincronizaciÃ³n AutomÃ¡tica (Windows)
```bash
sync-to-production.bat
```

### SincronizaciÃ³n Manual
```bash
# 1. Ejecutar tests
pytest -q

# 2. Hacer commit de cambios
git add .
git commit -m "feat: nueva funcionalidad"

# 3. Push a desarrollo
git push origin main

# 4. Sincronizar con producciÃ³n
git push production main
```

## ğŸ› ï¸ Herramientas Disponibles

### Scripts de Testing
- `test_quick.py`: Tests bÃ¡sicos de conexiÃ³n y funcionalidad
- `run_tests.py`: Tests completos de la API
- `pytest`: Framework de testing completo

### Scripts de Base de Datos
- `populate_database.py`: Poblar la base de datos con datos de prueba
- `clear_database.py`: Limpiar todas las solicitudes de la base de datos

### Scripts de SincronizaciÃ³n
- `sync-to-production.bat`: SincronizaciÃ³n automÃ¡tica (Windows)
- `sync-to-production.sh`: SincronizaciÃ³n automÃ¡tica (Linux/Mac)

### ConfiguraciÃ³n
- `pytest.ini`: ConfiguraciÃ³n de pytest
- `requirements-test.txt`: Dependencias de testing

## ğŸ“ Estructura del Proyecto

```
solicitudes-service-dev/
â”œâ”€â”€ app/                    # CÃ³digo principal de la aplicaciÃ³n
â”œâ”€â”€ tests/                  # Tests de la aplicaciÃ³n
â”œâ”€â”€ development-files/      # Archivos de desarrollo (no se sincronizan)
â”œâ”€â”€ requirements.txt        # Dependencias principales
â”œâ”€â”€ requirements-test.txt   # Dependencias de testing
â”œâ”€â”€ pytest.ini            # ConfiguraciÃ³n de pytest
â”œâ”€â”€ test_quick.py         # Tests rÃ¡pidos
â”œâ”€â”€ run_tests.py          # Tests completos
â”œâ”€â”€ sync-to-production.bat # Script de sincronizaciÃ³n (Windows)
â””â”€â”€ TESTING.md            # Este archivo
```

## ğŸ”§ Flujo de Trabajo

### 1. Desarrollo
- Trabaja en el cÃ³digo en la carpeta `app/`
- Escribe tests en la carpeta `tests/`
- Usa `test_quick.py` para verificaciones rÃ¡pidas

### 2. Testing
- Ejecuta tests antes de cada commit
- Usa `pytest` para tests completos
- Verifica que todos los tests pasen

### 3. SincronizaciÃ³n
- Usa `sync-to-production.bat` para sincronizar automÃ¡ticamente
- O haz push manual a ambos repositorios

### 4. Despliegue
- El repositorio de producciÃ³n se mantiene limpio
- Solo contiene cÃ³digo de producciÃ³n
- Se despliega automÃ¡ticamente desde producciÃ³n

## ğŸš¨ Troubleshooting

### Error: "No se encontrÃ³ remote 'production'"
```bash
git remote add production https://github.com/CobrasOrg/solicitudes-service.git
```

### Error: "Los tests fallaron"
- Revisa que MongoDB estÃ© corriendo
- Verifica las variables de entorno
- Ejecuta `python test_quick.py` para diagnÃ³stico

### Error: "Error al sincronizar con producciÃ³n"
- Verifica permisos de escritura en el repositorio de producciÃ³n
- AsegÃºrate de estar autenticado con GitHub
- Revisa que el repositorio de producciÃ³n exista

## ğŸ“Š Monitoreo

### Logs de Testing
```bash
# Tests con verbose
pytest -v

# Tests con output detallado
pytest -s

# Tests con coverage
pytest --cov=app --cov-report=html
```

### Estado de SincronizaciÃ³n
```bash
# Verificar remotes
git remote -v

# Verificar estado de commits
git log --oneline -10
```

## ğŸ¯ PrÃ³ximos Pasos

1. âœ… Configurar repositorio de desarrollo
2. âœ… Instalar dependencias de testing
3. âœ… Configurar remote de producciÃ³n
4. ğŸ”„ Ejecutar tests iniciales
5. ğŸ”„ Comenzar desarrollo con testing completo
6. ğŸ”„ Configurar CI/CD si es necesario

## ğŸ“ Soporte

Si tienes problemas:
1. Revisa los logs de error
2. Ejecuta `python test_quick.py` para diagnÃ³stico
3. Verifica la configuraciÃ³n de MongoDB
4. Revisa las variables de entorno

---

**Nota**: Este repositorio contiene archivos de desarrollo que NO se sincronizan con producciÃ³n. El repositorio de producciÃ³n se mantiene limpio y optimizado para despliegue. 